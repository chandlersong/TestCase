jar.enabled = false
sourceSets {
    main {
        java {
            srcDirs = []
        }
        resources {
            srcDirs = []
        }
    }
    test {
        java {
            srcDirs = []
        }
        resources {
            srcDirs = []
        }
    }
}

subprojects {

    apply plugin: 'application'

    dependencies {
        api "org.apache.logging.log4j:log4j-api:${log4jVersion}"
        api "org.apache.logging.log4j:log4j-core:${log4jVersion}"
        api "org.apache.logging.log4j:log4j-slf4j-impl:${log4jVersion}"
        api "org.slf4j:slf4j-log4j12:${slf4jVersion}"
        compileOnly "org.apache.spark:spark-sql_2.12:${sparkVersion}"
    }

    jar {
        manifest {
            attributes 'Built-By': System.getProperty('user.name'),
                    'Build-Jdk': System.getProperty('java.version')
        }
    }

    task getInMiniKubeIp{
        getInMiniKubeIp.ext.ip = new ByteArrayOutputStream()
        exec {
            commandLine 'minikube', 'ip'
            standardOutput =  getInMiniKubeIp.ext.ip
        }
        println "minikube ip is $getInMiniKubeIp.ext.ip"
    }

    task execInMiniKube(type: ExecInRemote){
        dependsOn getInMiniKubeIp
        def ip = getInMiniKubeIp.ip
        remote "spark://"+ip.toString().substring(0, ip.toString().length()-1)+":"+remotePort
    }

}

class ExecInRemote extends Exec {
    String jarPath
    String remote
    String mainClass

    ExecInRemote() {
        commandLine 'spark-submit', '--class',"${->mainClass}", \
                    "--master","${->remote}", \
                    "${->jarPath}"
    }
}

